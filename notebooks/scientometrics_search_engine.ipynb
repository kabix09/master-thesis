{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01a8400-5267-4dd5-a990-dee8d8f666a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a215b64-f49e-4977-ae7c-0607c057c5e0",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "51621b63-98bc-49a3-981e-411bded57aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytaj dane z pliku CSV\n",
    "csv_file_path = \"../data/interim//articles_with_score_df.csv\"\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b40a88f-e4bf-4a18-97a6-ef0862782d75",
   "metadata": {},
   "source": [
    "### Prepare embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e805685-548e-4da8-9531-a54705801bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 850406/850406 [1:27:03<00:00, 162.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available: \", torch.cuda.is_available())   \n",
    "    print(\"Number of CUDA devices: \", torch.cuda.device_count())\n",
    "    print(\"CUDA current device: \", torch.cuda.current_device())\n",
    "    print(\"CUDA device name: \", torch.cuda.get_device_name(0))\n",
    "\n",
    "    # Utwórz instancję modelu SentenceTransformer\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\", device='cuda')\n",
    "else:\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\", device='cpu')\n",
    "\n",
    "# Zanurzenie tytułów\n",
    "titles = df['title'].tolist()\n",
    "\n",
    "titles_embeddings = []\n",
    "\n",
    "for title in tqdm(titles):\n",
    "    embedding = model.encode([title])\n",
    "    titles_embeddings.append(embedding[0])\n",
    "\n",
    "df['embedding'] = titles_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530c4c4f-80d2-42b1-9c47-6dcafa0d928f",
   "metadata": {},
   "source": [
    "## Load data to Vector DB (chroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cedaaa9-9650-4dec-bf3b-a88d3fc39169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "chroma_client = chromadb.HttpClient(host=\"localhost\", port=8000, settings=Settings(allow_reset=True, anonymized_telemetry=False))\n",
    "\n",
    "collection_status = False\n",
    "while collection_status != True:\n",
    "    try:\n",
    "        document_collection = chroma_client.get_or_create_collection(name=\"articles_with_score\")\n",
    "        collection_status = True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "790d6c53-1b5c-4fc6-a10a-51cb8ce0216c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████████████████████████████████████████████████████████████████| 86/86 [27:16<00:00, 19.03s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last confirmed ID: 850406\n",
      "Size of the collection: 850406\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "last_confirmed_id = 0\n",
    "\n",
    "# Dzielimy DataFrame na tablice po 10 000 elementów\n",
    "for batch_start in tqdm(range(0, df.shape[0], batch_size), desc='Batches', unit='batch'):\n",
    "    batch_df = df.iloc[batch_start:batch_start + batch_size]\n",
    "\n",
    "    # Pobieramy listę embeddingów, dokumentów, metadanych i id dla bieżącej partii\n",
    "    batch_embeddings = batch_df['embedding'].apply(lambda x: x.tolist()).tolist()\n",
    "    batch_documents = batch_df['title'].tolist()\n",
    "    batch_metadatas = [{'year': row['year'], 'n_citation': row['n_citation'], 'gov_score': row['gov_score']} for index, row in batch_df.iterrows()]\n",
    "    batch_ids = [str(index + 1) for index in batch_df.index]\n",
    "    \n",
    "    # Dodajemy partię danych do kolekcji\n",
    "    document_collection.add(\n",
    "        embeddings=batch_embeddings,\n",
    "        documents=batch_documents,\n",
    "        metadatas=batch_metadatas,\n",
    "        ids=batch_ids\n",
    "    )\n",
    "\n",
    "    # Aktualizujemy last_confirmed_id\n",
    "    last_confirmed_id = batch_df.index[-1] + 1\n",
    "\n",
    "# Wypisz ostatnio potwierdzone ID\n",
    "# print(\"Last confirmed ID:\", last_confirmed_id)\n",
    "\n",
    "# Sprawdzamy rozmiar kolekcji\n",
    "try:\n",
    "    collection_size = document_collection.count()\n",
    "    print(\"Size of the collection:\", collection_size)\n",
    "except Exception as e:\n",
    "    print(\"Failed to get collection size:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "925d1178-bea0-44f5-b498-0f3bbfbc282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usuwamy dataset aby opróżnić pamięć RAM\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac90d5b1-c9a3-43f5-b9be-4774eb004878",
   "metadata": {},
   "source": [
    "### Health check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c9d8e239-390c-4015-ab00-9cbf17522636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct size of the articles collection: 850406\n"
     ]
    }
   ],
   "source": [
    "if document_collection.count() == df.shape[0]:\n",
    "    print(\"Correct size of the articles collection:\", document_collection.count())\n",
    "else:\n",
    "    print(\"Data inconsistency detected!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a8765-a985-4d06-98f2-3724509c22f5",
   "metadata": {},
   "source": [
    "## Word collection initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3fec2a-3270-4d9e-91a6-c1b7a67fca99",
   "metadata": {},
   "source": [
    "In this section collection of `verb`, `noun`, `adjectives` and `participles` were prepared. These will later be used to build random impressions and phrases. To achive this we will use the **spacy** library.\n",
    "\n",
    "The previously mentioned collections will be stored in the form of a dictionary due to the indexing properties of this data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f95a76bf-664c-449e-94ce-354dcb090580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 850406/850406 [6:07:14<00:00, 38.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verb dictionary:\n",
      "6459\n",
      "\n",
      "Dictionary of nouns:\n",
      "49604\n",
      "\n",
      "Dictionary of adjectives:\n",
      "21932\n",
      "\n",
      "Dictionary of participles:\n",
      "6049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "dict_verb = {}\n",
    "dict_noun = {}\n",
    "dict_adj = {}\n",
    "dict_ger = {}\n",
    "\n",
    "# Create new `pandas` methods which use `tqdm` progress\n",
    "# (can use tqdm_gui, optional kwargs, etc.)\n",
    "tqdm.pandas()\n",
    "\n",
    "titles_data = document_collection.get()\n",
    "title_df = pd.DataFrame({'title': titles_data['documents']})\n",
    "\n",
    "spacy.require_gpu()\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def process_titles(title):\n",
    "    document = nlp(title)\n",
    "\n",
    "    for token in document:\n",
    "        # Ignore punctuation marks and whitespaces\n",
    "        if not token.is_punct and not token.is_space:\n",
    "            lemma = token.lemma_\n",
    "\n",
    "            # 1. Imiesłowy czasownikowe:\n",
    "            # - Imiesłowy bierny (czasownik bierny): Tag VBN (Past participle)\n",
    "            # - Imiesłowy czynny (czasownik czynny): Tag VBG (Gerund or present participle)\n",
    "            # 2. imiesłowy przymiotnikowe\n",
    "            # - Imiesłowy bierny (przymiotnik bierny): VAPP (perfect participle, auxiliary)\n",
    "            # - Imiesłowy czynny (przymiotnik czynny): VMPP (perfect participle, modal)\n",
    "            # - VVPP (perfect participles)\n",
    "            # 3. Imiesłowy przymiotnikowe:\n",
    "            #    np \"running shoes\"\n",
    "            if token.pos_ == \"VERB\" and token.tag_ in [\"VBN\", \"VBG\"]:\n",
    "                dict_ger[lemma] = lemma\n",
    "            elif token.pos_ == \"VERB\":\n",
    "                dict_verb[lemma] = lemma\n",
    "            elif token.pos_ == \"ADJ\" and token.tag_ in [\"VAPP\", \"VMPP\", \"VVPP\"]:\n",
    "                dict_ger[lemma] = lemma\n",
    "            elif token.pos_ == \"ADJ\":\n",
    "                dict_adj[lemma] = lemma\n",
    "            elif token.pos_ == \"NOUN\" and token.tag_ == \"VBG\":\n",
    "                dict_ger[lemma] = lemma\n",
    "            elif token.pos_ == \"NOUN\":\n",
    "                dict_noun[lemma] = lemma\n",
    "\n",
    "# Processing titles and building dictionaries\n",
    "title_df['title'].progress_apply(process_titles)\n",
    "\n",
    "# Summary\n",
    "print(\"Verb dictionary:\")\n",
    "print(len(dict_verb))\n",
    "print(\"\\nDictionary of nouns:\")\n",
    "print(len(dict_noun))\n",
    "print(\"\\nDictionary of adjectives:\")\n",
    "print(len(dict_adj))\n",
    "print(\"\\nDictionary of participles:\")\n",
    "print(len(dict_ger))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1309220e-059e-4e87-ae5b-c181cbba9112",
   "metadata": {},
   "source": [
    "**Note**\n",
    "Removing more than 41 666 records at once throw error:\n",
    "\n",
    "Error adding noun collection: {\"error\":\"ValueError('Cannot submit more than 41,666 embeddings at once. Please submit your embeddings in batches of size 41,666 or less.')\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ee79ad0-f599-4ae7-8f24-b151d6da8eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "verbs: 100%|██████████████████████████████████████████████████████████████████████████| 7/7 [02:59<00:00, 25.65s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "noun: 100%|█████████████████████████████████████████████████████████████████████████| 50/50 [23:19<00:00, 27.98s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjectives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adjectives: 100%|███████████████████████████████████████████████████████████████████| 22/22 [10:13<00:00, 27.89s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gerounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gerounds: 100%|███████████████████████████████████████████████████████████████████████| 7/7 [02:56<00:00, 25.18s/batch]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "collections = {\n",
    "    \"verbs\": dict_verb,\n",
    "    \"noun\": dict_noun,\n",
    "    \"adjectives\": dict_adj,\n",
    "    \"gerounds\": dict_ger\n",
    "}\n",
    "\n",
    "for collection_name, collection_data in collections.items():\n",
    "    batch_size = 1000\n",
    "    last_confirmed_id = 0\n",
    "\n",
    "    print(collection_name)\n",
    "    try:\n",
    "        connection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "        # Clear collection\n",
    "        if connection.count() > 0:\n",
    "            print(connection.count())\n",
    "            ids = connection.get()['ids']\n",
    "            for start_idx in range(0, len(ids), batch_size * 10):\n",
    "                connection.delete(ids[start_idx:start_idx + batch_size * 10])\n",
    "\n",
    "        # Add new data\n",
    "        words_collection = list(collection_data.keys())\n",
    "        for start_idx in tqdm(range(0, len(words_collection), batch_size), desc=collection_name, unit='batch'):\n",
    "            collection_element = words_collection[start_idx:start_idx + batch_size]\n",
    "            connection.add(documents=collection_element, ids=collection_element)\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding {collection_name} collection: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2ff704a-0a6c-4d42-a5cb-02fce1029849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--in',\n",
       " '-PAM',\n",
       " '-approach',\n",
       " '-assignment',\n",
       " '-base',\n",
       " '-binomial',\n",
       " '-conjugate',\n",
       " '-constraine',\n",
       " '-design',\n",
       " '-fold',\n",
       " '-from',\n",
       " '-hard',\n",
       " '-hypermodule',\n",
       " '-induce',\n",
       " '-linear',\n",
       " '-linke',\n",
       " '-opt',\n",
       " '-oriente',\n",
       " '-pairwise',\n",
       " '-perfect',\n",
       " '-pseudo',\n",
       " '-term',\n",
       " '-wise',\n",
       " '103lr',\n",
       " '1839–1910',\n",
       " '1T1C',\n",
       " '2T2C',\n",
       " '2d',\n",
       " '3)^{\\\\ast}$',\n",
       " '3D',\n",
       " '3d',\n",
       " '3did',\n",
       " '3gpp',\n",
       " '4BOK',\n",
       " '4RTD',\n",
       " '=',\n",
       " '@trust',\n",
       " 'ABINIT',\n",
       " 'ACSE',\n",
       " 'ADOPEL',\n",
       " 'AGGLOMERATIVE',\n",
       " 'ALGORITHM',\n",
       " 'ASSIGNMENT',\n",
       " 'ATGC',\n",
       " 'ATTENTIONAL',\n",
       " 'AUDIO',\n",
       " 'AWGN',\n",
       " 'AssociatesISBN',\n",
       " 'AutoGraphiX',\n",
       " 'BIND',\n",
       " 'BLAST',\n",
       " 'BODB',\n",
       " 'BPEL',\n",
       " 'BROADCAST',\n",
       " 'BURST',\n",
       " 'BioBIKE',\n",
       " 'BioSAVE',\n",
       " 'Burst',\n",
       " 'CARSA',\n",
       " 'CATASTROPHIC',\n",
       " 'CEREVISIAE',\n",
       " 'CHEBYSHEV',\n",
       " 'CIFEr',\n",
       " 'CIRCULANT',\n",
       " 'CLONE',\n",
       " 'CMMI',\n",
       " 'COEFFICIENT',\n",
       " 'COLONY',\n",
       " 'COLOR',\n",
       " 'COMPLEX',\n",
       " 'CONSTANT',\n",
       " 'CONTRAST',\n",
       " 'CONTROLLER',\n",
       " 'COULD',\n",
       " 'CREATIVITY',\n",
       " 'CRITERIA',\n",
       " 'CRYPTOGRAPHIC',\n",
       " 'CUBE',\n",
       " 'CURVE',\n",
       " 'CaIrO3',\n",
       " 'Canonical-',\n",
       " 'CircaDB',\n",
       " 'Cl',\n",
       " 'Cost',\n",
       " 'D0C',\n",
       " 'D2/3',\n",
       " 'DAIDA',\n",
       " 'DANTE',\n",
       " 'DASH',\n",
       " 'DATA',\n",
       " 'DATASTAR',\n",
       " 'DATENTYPEN',\n",
       " 'DCMTB',\n",
       " 'DCOP',\n",
       " 'DDBHMM',\n",
       " 'DDRC',\n",
       " 'DECREASE',\n",
       " 'DEHN',\n",
       " 'DENSE',\n",
       " 'DENSITY',\n",
       " 'DEOXYMYOGLOBIN',\n",
       " 'DEPENDENT',\n",
       " 'DESIGN',\n",
       " 'DIAGRAM',\n",
       " 'DIFFREALWAVE',\n",
       " 'DISCRIMINANT',\n",
       " 'DMB',\n",
       " 'DO',\n",
       " 'DPEL',\n",
       " 'DS18B20',\n",
       " 'DT',\n",
       " 'Decompose',\n",
       " 'Degree-$k$',\n",
       " 'Do',\n",
       " 'DroID',\n",
       " 'EADFB',\n",
       " 'ECoG}$',\n",
       " 'EDCA',\n",
       " 'EDIT',\n",
       " 'EDUA',\n",
       " 'EFFICIENT',\n",
       " 'EFFORT',\n",
       " 'EGFET',\n",
       " 'EKHARA',\n",
       " 'EMBL',\n",
       " 'EMBODIMENT',\n",
       " 'ENUMERATIONEN',\n",
       " 'ENVIRONMENT',\n",
       " 'EQUILIBRIA',\n",
       " 'ERROR',\n",
       " 'ESPRIT',\n",
       " 'ESTHER',\n",
       " 'ESTIMATOR',\n",
       " 'EXAMPLE',\n",
       " 'EXIN',\n",
       " 'EXPLICIT',\n",
       " 'EXTRABOARD',\n",
       " 'EXTREMAL',\n",
       " 'EXTREME',\n",
       " 'E^2',\n",
       " 'ElasticO++',\n",
       " 'EndA',\n",
       " 'FACE',\n",
       " 'FAULT',\n",
       " 'FMCW',\n",
       " 'FO(C',\n",
       " 'FOPEN',\n",
       " 'FOREWORD',\n",
       " 'FREE',\n",
       " 'FSIM',\n",
       " 'FSSP',\n",
       " 'G/1',\n",
       " 'GHz',\n",
       " 'GREEK',\n",
       " 'GSVD',\n",
       " 'Generalized-',\n",
       " 'GtRNAdb',\n",
       " 'H1',\n",
       " 'HANDBOOK',\n",
       " 'HAPPEL',\n",
       " 'HAVE',\n",
       " 'HCOP',\n",
       " 'HLLC',\n",
       " 'HOMOMORPHIC',\n",
       " 'HORIZON',\n",
       " 'HYDROLOGY',\n",
       " 'HYPERCUBE',\n",
       " 'HZSM‐5',\n",
       " 'H^2',\n",
       " 'HfO2',\n",
       " 'HyPA',\n",
       " 'H∞',\n",
       " 'IAP',\n",
       " 'ICEM',\n",
       " 'ICI',\n",
       " 'ICMA@email.sjsu.edu',\n",
       " 'ICSSP',\n",
       " 'IDCT',\n",
       " 'IDEAL',\n",
       " 'IETF',\n",
       " 'IGBT',\n",
       " 'IGDT',\n",
       " 'IM',\n",
       " 'INDEX',\n",
       " 'INDOOR',\n",
       " 'INFOGRAPHIC',\n",
       " 'INJECTIVITY',\n",
       " 'INSTABILITY',\n",
       " 'INTENSIVE',\n",
       " 'INTERFACE',\n",
       " 'INTERVAL',\n",
       " 'IPv4',\n",
       " 'IQp',\n",
       " 'ISBN',\n",
       " 'ISFV14',\n",
       " 'ISI‐CD',\n",
       " 'ISPIDER',\n",
       " 'ISTFT',\n",
       " 'InSAR',\n",
       " 'InSatDb',\n",
       " 'IrLAP',\n",
       " 'JPIP',\n",
       " 'JTCP',\n",
       " 'KOLMOGOROV',\n",
       " 'LAAP',\n",
       " 'LARC',\n",
       " 'LEAST',\n",
       " 'LEAVE',\n",
       " 'LEXICOGRAPHIC',\n",
       " 'LIEB',\n",
       " 'LOAD',\n",
       " 'LORE',\n",
       " 'LOSSY',\n",
       " 'LOÈVE',\n",
       " 'LR+Th',\n",
       " 'LS_SVM',\n",
       " \"LUR'E\",\n",
       " 'LiMTO',\n",
       " 'MAGI',\n",
       " 'MANIPULATOR',\n",
       " 'MAPEL',\n",
       " 'MCRLB',\n",
       " 'MDCT',\n",
       " 'MEMPSODE',\n",
       " 'METHODOLOGY',\n",
       " 'MICAz',\n",
       " 'MINIMAL',\n",
       " 'MISO',\n",
       " 'MLD',\n",
       " 'MODAL',\n",
       " 'MONADIC',\n",
       " 'MORPHOLOGIC',\n",
       " 'MOSAIC',\n",
       " 'MPEG-7',\n",
       " 'MPTCP',\n",
       " 'MULTIMODAL',\n",
       " 'MULTIPROCESSOR',\n",
       " 'MVDR',\n",
       " 'Matroïde',\n",
       " 'MicroFix',\n",
       " 'Mischdichten',\n",
       " 'NACR',\n",
       " 'NBTI',\n",
       " 'NSGA',\n",
       " 'NTCP',\n",
       " 'NTUplace3',\n",
       " 'Nets1',\n",
       " 'OLAP',\n",
       " 'ON',\n",
       " 'ONTOLOGY',\n",
       " 'OOK',\n",
       " 'OPNEX',\n",
       " 'OPTIMALLY',\n",
       " 'ORDER',\n",
       " 'ORGANISATIONAL',\n",
       " 'OTDM',\n",
       " 'OVERLAP',\n",
       " 'OntoUML',\n",
       " 'Opusc',\n",
       " 'P+N',\n",
       " 'PAPR',\n",
       " 'PASCH',\n",
       " 'PAST',\n",
       " 'PAT-',\n",
       " 'PBTI',\n",
       " 'PCPGSD',\n",
       " 'PERIODICALLY',\n",
       " 'PET',\n",
       " 'PIECE',\n",
       " 'PLAY',\n",
       " 'PNRD',\n",
       " 'POINT',\n",
       " 'POLYCOST',\n",
       " 'PRIVILEGE',\n",
       " 'PROBABILITY',\n",
       " 'PROBLEM',\n",
       " 'PROCESSOR',\n",
       " 'PROFALIGN',\n",
       " 'PUNITY',\n",
       " 'PURE',\n",
       " 'PYRAMIDAL',\n",
       " 'Parallel',\n",
       " 'PenalizedSVM',\n",
       " 'PhosphoPICK',\n",
       " 'Pose',\n",
       " 'ProteoModlR',\n",
       " 'Pulsewidth',\n",
       " 'QSAT',\n",
       " 'QUALITATIVE',\n",
       " 'QUANTILE',\n",
       " 'QUANTITY',\n",
       " 'QUICK',\n",
       " 'RADIOGRAPHIC',\n",
       " 'RANGE',\n",
       " 'RATIO',\n",
       " 'RAUMKOMPLIZIERTHEIT',\n",
       " 'RECURRENT',\n",
       " 'REDEX',\n",
       " 'REFLEX',\n",
       " 'RELATIVISTIC',\n",
       " 'REPRESENTATION',\n",
       " 'RESISTANT',\n",
       " 'REUSE',\n",
       " 'RII',\n",
       " 'RNASeqMetaDB',\n",
       " 'ROBIN',\n",
       " 'RS/6000',\n",
       " 'RSFQ',\n",
       " 'RULE',\n",
       " 'Rank-$(r_1,$',\n",
       " 'ReVeaLD',\n",
       " 'Read',\n",
       " 'RefProtDom',\n",
       " 'Researchers[From',\n",
       " 'SBMAC',\n",
       " 'SCHEDULER',\n",
       " 'SCIENAR',\n",
       " 'SDRAM',\n",
       " 'SEEM',\n",
       " 'SEMULATOR',\n",
       " 'SENSITIVE',\n",
       " 'SFESA',\n",
       " 'SGA',\n",
       " 'SHAPE',\n",
       " 'SHARP',\n",
       " 'SIACG',\n",
       " 'SIDEKICK',\n",
       " 'SISFET',\n",
       " 'SLDNF',\n",
       " 'SLEUTH',\n",
       " 'SLICK',\n",
       " 'SMOOTH',\n",
       " 'SOHO',\n",
       " 'SOIL',\n",
       " 'SOLVER',\n",
       " 'SORTEZ',\n",
       " 'SPEAKER',\n",
       " 'SPECTRUM',\n",
       " 'SPEECH',\n",
       " 'SPEEDABLE',\n",
       " 'SPREAD',\n",
       " 'SPTHEO',\n",
       " 'SSVM',\n",
       " 'STANDARD',\n",
       " 'STAT',\n",
       " 'STFT',\n",
       " 'STONE',\n",
       " 'STRATEGIC',\n",
       " 'STREAM',\n",
       " 'STRUCTURALLY',\n",
       " 'SUBJECTIVE',\n",
       " 'SUPERVALUATIONAL',\n",
       " 'SVPWM',\n",
       " 'SWITCH',\n",
       " 'SYSTEM',\n",
       " 'Sentinel-2',\n",
       " 'Services@MediGRID',\n",
       " 'Shermag',\n",
       " 'SilkSatDb',\n",
       " 'Space‐efficient',\n",
       " 'Spectra-',\n",
       " 'Spectrum',\n",
       " 'TAGGANT',\n",
       " 'TAKAGI',\n",
       " 'TARD',\n",
       " 'TAYLOR',\n",
       " 'TCAM',\n",
       " 'TCP',\n",
       " 'TEAM',\n",
       " 'TECHNIQUE',\n",
       " 'TMS320C6711',\n",
       " 'TOA',\n",
       " 'TOPEX',\n",
       " 'TOPOLOGY',\n",
       " 'TOSBURG',\n",
       " 'TRAPEZOIDAL',\n",
       " 'TRIZ',\n",
       " 'TYPE',\n",
       " 'Tap',\n",
       " 'Tax4Fun',\n",
       " 'Thome',\n",
       " 'Tier-2',\n",
       " 'Tissue–-A',\n",
       " 'TmaDB',\n",
       " 'T}}$',\n",
       " 'UDC',\n",
       " 'UNLV',\n",
       " 'USSD',\n",
       " 'Ultra3D',\n",
       " 'Ultratight',\n",
       " 'VALUE',\n",
       " 'VCSEL',\n",
       " 'VDSL',\n",
       " 'VIA',\n",
       " 'VIRsiRNAdb',\n",
       " 'VLAD',\n",
       " 'Verbrauchsverhalten',\n",
       " 'Via',\n",
       " 'WAERDEN',\n",
       " 'WAKSMAN',\n",
       " 'WDDD',\n",
       " 'WEATHER',\n",
       " 'WFPP',\n",
       " 'WICK',\n",
       " 'WORKFLOW',\n",
       " 'WSBPEL',\n",
       " 'Wentworth',\n",
       " 'WorldView-2',\n",
       " 'YPHON',\n",
       " 'ZETA',\n",
       " 'ZINDLER',\n",
       " '\\\\\"Got',\n",
       " '\\\\(AXB',\n",
       " '\\\\({\\\\varvec{l}}_{2}\\\\)-regularize',\n",
       " '\\\\alpha',\n",
       " '\\\\delta$',\n",
       " '\\\\eta',\n",
       " '\\\\mbi',\n",
       " '\\\\phi',\n",
       " '\\\\taunaf',\n",
       " '\\\\theta',\n",
       " '\\\\theta$',\n",
       " '^{0}$',\n",
       " '^{2}$',\n",
       " 'a',\n",
       " 'ab',\n",
       " 'abandonment',\n",
       " 'abc',\n",
       " 'abmash',\n",
       " 'abnormal',\n",
       " 'abolish',\n",
       " 'abort',\n",
       " 'abound',\n",
       " 'above',\n",
       " 'absolute',\n",
       " 'absorb',\n",
       " 'absorbent',\n",
       " 'abstract',\n",
       " 'abuse',\n",
       " 'abweichende',\n",
       " 'aby',\n",
       " 'abys',\n",
       " 'academia',\n",
       " 'accelerate',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accessorize',\n",
       " 'accessory',\n",
       " 'accommodate',\n",
       " 'accompany',\n",
       " 'accomplish',\n",
       " 'account',\n",
       " 'accumben',\n",
       " 'accumulate',\n",
       " 'accurate',\n",
       " 'acetate',\n",
       " 'acetylcholine',\n",
       " 'acgh',\n",
       " 'achieve',\n",
       " 'acknowledge',\n",
       " 'acme',\n",
       " 'acquire',\n",
       " 'act',\n",
       " 'actinide',\n",
       " 'action',\n",
       " 'activate',\n",
       " 'activation‐induce',\n",
       " 'active',\n",
       " 'activitie',\n",
       " 'activity',\n",
       " 'actuate',\n",
       " 'acute',\n",
       " 'acyclic',\n",
       " 'adapt',\n",
       " 'adaptare',\n",
       " 'adapter',\n",
       " 'adaptive',\n",
       " 'add',\n",
       " 'address',\n",
       " 'adduct',\n",
       " 'adenine',\n",
       " 'adherence',\n",
       " 'adipose',\n",
       " 'adjacencie',\n",
       " 'adjoint',\n",
       " 'adjust',\n",
       " 'administer',\n",
       " 'admit',\n",
       " 'admixkjump',\n",
       " 'adolescence',\n",
       " 'adopt',\n",
       " 'adult',\n",
       " 'adulthood',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advergame',\n",
       " 'advertise',\n",
       " 'advertisement',\n",
       " 'advise',\n",
       " 'advocate',\n",
       " 'aerosol',\n",
       " 'aerospace',\n",
       " 'affair',\n",
       " 'affdef',\n",
       " 'affect',\n",
       " 'affine',\n",
       " 'affinitie',\n",
       " 'afford',\n",
       " 'affymetrix',\n",
       " 'afpif',\n",
       " 'afsr',\n",
       " 'aftereffect',\n",
       " 'agename',\n",
       " 'agennt',\n",
       " 'agent‐base',\n",
       " 'agglomerate',\n",
       " 'aggregate',\n",
       " 'agonist',\n",
       " 'agora',\n",
       " 'agree',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'airborne',\n",
       " 'airport',\n",
       " 'airy',\n",
       " 'akzeptierbarkeitsgrade',\n",
       " 'al',\n",
       " 'alarm',\n",
       " 'albican',\n",
       " 'aldehyde',\n",
       " 'aleatoire',\n",
       " 'alert',\n",
       " 'alertnes',\n",
       " 'alertness',\n",
       " 'algebra',\n",
       " 'algebraic',\n",
       " 'algebrique',\n",
       " 'alginate',\n",
       " 'algol',\n",
       " 'algorithm',\n",
       " 'algorithme',\n",
       " 'algorithmic',\n",
       " 'algorithms',\n",
       " 'algorithmzoome',\n",
       " 'algèbre',\n",
       " 'algébrique',\n",
       " 'alice',\n",
       " 'align',\n",
       " 'alignment',\n",
       " 'alkaloid',\n",
       " 'alle',\n",
       " 'aller',\n",
       " 'allergen',\n",
       " 'alleviate',\n",
       " 'allgemeine',\n",
       " 'alliance',\n",
       " 'allocate',\n",
       " 'allocentric',\n",
       " 'allograph',\n",
       " 'allot',\n",
       " 'allow',\n",
       " 'alloy',\n",
       " 'alpha/-cut',\n",
       " 'alphabet',\n",
       " 'alter',\n",
       " 'alternan',\n",
       " 'alternate',\n",
       " 'alternatize',\n",
       " 'altitude',\n",
       " 'aluminium',\n",
       " 'aluminum',\n",
       " 'aléatoire',\n",
       " 'am',\n",
       " 'ambient',\n",
       " 'ambisense',\n",
       " 'ameliorate',\n",
       " 'amh',\n",
       " 'amide',\n",
       " 'amidoborane',\n",
       " 'amino',\n",
       " 'aminosubstitute',\n",
       " 'amisp',\n",
       " 'amoeba',\n",
       " 'amole',\n",
       " 'amortize',\n",
       " 'amount',\n",
       " 'amphetamine',\n",
       " 'amplify',\n",
       " 'amplitude',\n",
       " 'amyloid',\n",
       " 'anaerobe',\n",
       " 'analog',\n",
       " 'analogrechner',\n",
       " 'analogue',\n",
       " 'analyse',\n",
       " 'analysis',\n",
       " 'analysisof',\n",
       " 'analysis‐base',\n",
       " 'analytische',\n",
       " 'analyze',\n",
       " 'anarchy',\n",
       " 'anchor',\n",
       " 'ancile',\n",
       " 'aneuploid',\n",
       " 'anfis',\n",
       " 'angiogenesis',\n",
       " 'angle',\n",
       " 'animal',\n",
       " 'animate',\n",
       " 'anisotropic',\n",
       " 'ann',\n",
       " 'anneal',\n",
       " 'annihilate',\n",
       " 'annotate',\n",
       " 'announce',\n",
       " 'annularen',\n",
       " 'annuum',\n",
       " 'anomalie',\n",
       " 'anonymize',\n",
       " 'answer',\n",
       " 'antagonise',\n",
       " 'ante',\n",
       " 'antecedent',\n",
       " 'antenna',\n",
       " 'antenna‐assiste',\n",
       " 'anterograde',\n",
       " 'anthracene',\n",
       " 'antialiase',\n",
       " 'antialiased',\n",
       " 'antibodie',\n",
       " 'antibody',\n",
       " 'antichain',\n",
       " 'anticipate',\n",
       " 'antidepressant',\n",
       " 'antigen',\n",
       " 'antiparticle',\n",
       " 'anycast',\n",
       " 'aoa',\n",
       " 'aoba',\n",
       " 'aperture',\n",
       " 'aplicado',\n",
       " 'apnea',\n",
       " 'apolipoprotein',\n",
       " 'apoptosis',\n",
       " 'appatp',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'applause',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'appraise',\n",
       " 'appreciate',\n",
       " 'approach',\n",
       " 'approachability',\n",
       " 'appropriate',\n",
       " 'approve',\n",
       " 'approximate',\n",
       " 'approximationof',\n",
       " 'aqua',\n",
       " 'arbiter',\n",
       " 'arbitrate',\n",
       " 'arcangelc',\n",
       " 'archaeal',\n",
       " 'archimate',\n",
       " 'architect',\n",
       " 'architecte',\n",
       " 'architecture',\n",
       " 'archive',\n",
       " 'are',\n",
       " 'areal',\n",
       " 'argue',\n",
       " 'arguesienne',\n",
       " 'argumentation',\n",
       " 'arid',\n",
       " 'arise',\n",
       " 'arithmetic',\n",
       " 'arm',\n",
       " 'armature',\n",
       " 'armchair',\n",
       " 'aroma',\n",
       " 'arrange',\n",
       " 'arrangement',\n",
       " 'array',\n",
       " 'arraycghbase',\n",
       " 'arrhythmia',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'artefact',\n",
       " 'article',\n",
       " 'articulate',\n",
       " 'articulatory',\n",
       " 'artifact',\n",
       " 'asac',\n",
       " 'asar',\n",
       " 'asaview',\n",
       " 'ascertain',\n",
       " 'ascribe',\n",
       " 'ask',\n",
       " 'asm',\n",
       " 'asp.net',\n",
       " 'aspect',\n",
       " 'asphalt',\n",
       " 'asphaltene',\n",
       " 'aspirate',\n",
       " 'aspiration',\n",
       " 'aspire',\n",
       " 'assat',\n",
       " 'assay',\n",
       " 'assemblage',\n",
       " 'assemble',\n",
       " 'assess',\n",
       " 'assessment',\n",
       " 'asset',\n",
       " 'assign',\n",
       " 'assignee',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'associate',\n",
       " 'associative',\n",
       " 'associee',\n",
       " 'associf',\n",
       " 'assume',\n",
       " 'assure',\n",
       " 'aster',\n",
       " 'asymmetry',\n",
       " 'asymptotique',\n",
       " 'atherogenesis',\n",
       " 'atlase',\n",
       " 'atmosphere',\n",
       " 'atoll',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attain',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attenuate',\n",
       " 'attitude',\n",
       " 'attract',\n",
       " 'attribute',\n",
       " 'attribute‐base',\n",
       " 'attune',\n",
       " 'au',\n",
       " 'auch',\n",
       " 'aucheri',\n",
       " 'auction',\n",
       " 'audit',\n",
       " 'augment',\n",
       " 'ausfürhrbare',\n",
       " 'australis',\n",
       " 'authenticate',\n",
       " 'author',\n",
       " 'autoencoder',\n",
       " 'automata',\n",
       " 'automate',\n",
       " 'automation',\n",
       " 'automatisierte',\n",
       " 'automorphisme',\n",
       " 'autonomy',\n",
       " 'autoregressive',\n",
       " 'auto‐correlate',\n",
       " 'avatar',\n",
       " 'average',\n",
       " 'avert',\n",
       " 'avicena',\n",
       " 'avoid',\n",
       " 'await',\n",
       " 'award',\n",
       " 'awareness',\n",
       " 'axiom',\n",
       " 'axiomatizable',\n",
       " 'axioms',\n",
       " 'axis',\n",
       " 'ayant',\n",
       " 'azurin',\n",
       " 'b)-code',\n",
       " 'b.i.p.',\n",
       " 'b_1',\n",
       " 'b_{n}-operator',\n",
       " 'ba',\n",
       " 'baboon',\n",
       " 'back',\n",
       " 'backbone',\n",
       " 'backfire',\n",
       " 'backhaul',\n",
       " 'backordere',\n",
       " 'backscatter',\n",
       " 'bake',\n",
       " 'balance',\n",
       " 'balancierte',\n",
       " 'bam',\n",
       " 'bammds',\n",
       " 'ban',\n",
       " 'band',\n",
       " 'bandlimite',\n",
       " 'bandpass',\n",
       " 'bandstop',\n",
       " 'bandwidth',\n",
       " 'bandwidth‐aware',\n",
       " 'bankless',\n",
       " 'bar',\n",
       " 'barcode',\n",
       " 'bark',\n",
       " 'barne',\n",
       " 'barycentric',\n",
       " 'base',\n",
       " 'baseline',\n",
       " 'basketball',\n",
       " 'bat',\n",
       " 'batch',\n",
       " 'bathe',\n",
       " 'batio3',\n",
       " 'bauhaus',\n",
       " 'bayesian',\n",
       " 'bbn',\n",
       " 'be',\n",
       " 'beadarray',\n",
       " 'beam',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'beatrix',\n",
       " 'become',\n",
       " 'bedside',\n",
       " 'beep',\n",
       " 'begin',\n",
       " 'behave',\n",
       " 'behaviour',\n",
       " 'bei',\n",
       " 'bela',\n",
       " 'belief1',\n",
       " 'believe',\n",
       " 'bell',\n",
       " 'belong',\n",
       " 'benchmark',\n",
       " 'bend',\n",
       " 'bender',\n",
       " 'benefit',\n",
       " 'benzoate',\n",
       " 'beobachterbasierter',\n",
       " 'berge',\n",
       " 'bespoke',\n",
       " 'best',\n",
       " 'best-',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'betreffend',\n",
       " 'betrieblicher',\n",
       " 'better',\n",
       " 'betwixt',\n",
       " 'beware',\n",
       " 'beyond',\n",
       " 'bi',\n",
       " 'bias',\n",
       " 'bicentere',\n",
       " 'biclique',\n",
       " 'biclose',\n",
       " 'bicm',\n",
       " 'biconnect',\n",
       " 'biconnecte',\n",
       " 'biconnected',\n",
       " 'bicycle',\n",
       " 'bid',\n",
       " 'bidentate',\n",
       " 'bie',\n",
       " 'bifinite',\n",
       " 'biframe',\n",
       " 'bifurcation',\n",
       " 'bilayere',\n",
       " 'bildbasierte',\n",
       " 'bilevel',\n",
       " 'bilinear',\n",
       " 'billboards',\n",
       " 'bimodal',\n",
       " 'bin',\n",
       " 'binaire',\n",
       " 'binarise',\n",
       " 'bind',\n",
       " 'binobjective',\n",
       " 'binormalize',\n",
       " 'bio',\n",
       " 'bioassay',\n",
       " 'biobjective',\n",
       " 'biobrick',\n",
       " 'bioinformatic',\n",
       " 'bioinformaticist',\n",
       " 'bioinspire',\n",
       " 'biomarker',\n",
       " 'biomechanically‐base',\n",
       " 'biomedicine',\n",
       " 'biopsy',\n",
       " 'biosurveillance',\n",
       " 'biosynthesis',\n",
       " 'biosystem',\n",
       " 'bipartite',\n",
       " 'bipe',\n",
       " 'biped',\n",
       " 'birth',\n",
       " 'bisect',\n",
       " 'bispectrum',\n",
       " 'bit',\n",
       " 'bitext',\n",
       " 'bitline',\n",
       " 'bitmap',\n",
       " 'bitrade',\n",
       " 'bits',\n",
       " 'bitwise',\n",
       " 'bivariate',\n",
       " 'bjørdal',\n",
       " 'bladder',\n",
       " 'blade',\n",
       " 'blame',\n",
       " 'blanker',\n",
       " 'blanket',\n",
       " 'blast',\n",
       " 'bleed',\n",
       " 'blend',\n",
       " 'bless',\n",
       " 'blind',\n",
       " 'blink',\n",
       " 'bliss',\n",
       " 'bloat',\n",
       " 'block',\n",
       " 'blockwise',\n",
       " 'blog',\n",
       " 'blogs',\n",
       " 'blong',\n",
       " 'blow',\n",
       " 'blue‐green',\n",
       " 'blur',\n",
       " 'board',\n",
       " 'bolometer',\n",
       " 'bolzano',\n",
       " 'bond',\n",
       " 'bondy',\n",
       " 'boneroute',\n",
       " 'booksize',\n",
       " 'boost',\n",
       " 'bootstrap',\n",
       " 'bootstrappe',\n",
       " 'borate',\n",
       " 'border',\n",
       " 'boreal',\n",
       " 'boronyl',\n",
       " 'borrow',\n",
       " 'bother',\n",
       " 'botnet',\n",
       " 'botswana',\n",
       " 'bottleneck',\n",
       " 'bottom',\n",
       " 'bounce',\n",
       " 'bound',\n",
       " 'bounding',\n",
       " 'bovine',\n",
       " 'bowel',\n",
       " 'box',\n",
       " 'boxB',\n",
       " 'box¿jenkin',\n",
       " 'bplg',\n",
       " 'bracket',\n",
       " 'braid',\n",
       " 'braille',\n",
       " 'brain',\n",
       " 'brainnetome',\n",
       " 'brainware',\n",
       " 'brake',\n",
       " 'branch',\n",
       " 'branchwidth',\n",
       " 'brass',\n",
       " 'brassinosteroid',\n",
       " 'braze',\n",
       " 'breach',\n",
       " 'breadcrumb',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakthrough',\n",
       " 'breastfeed',\n",
       " 'breathe',\n",
       " 'breed',\n",
       " 'brevis',\n",
       " 'bricole',\n",
       " 'bridge',\n",
       " 'brief',\n",
       " 'briggsae',\n",
       " 'brightness',\n",
       " 'bring',\n",
       " 'briscoe',\n",
       " 'brittle',\n",
       " 'broadband',\n",
       " 'broadcast',\n",
       " 'brook',\n",
       " 'brosemweb',\n",
       " 'browse',\n",
       " 'brush',\n",
       " 'brushless',\n",
       " 'bubble',\n",
       " 'buchholz',\n",
       " 'buffer',\n",
       " 'build',\n",
       " 'bulk',\n",
       " ...]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### TEST COLLECTION READ\n",
    "verbs_connection = chroma_client.get_or_create_collection(name=\"verbs\")\n",
    "display(verbs_connection.get()['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea4f7e-8d1f-4932-8724-e9aa38f82d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuda SPACY Help Links\n",
    "# https://learn.microsoft.com/en-us/answers/questions/1398254/installed-visual-studio-build-tools-but-cannot-fin\n",
    "# https://stackoverflow.com/questions/70840683/installed-visual-studio-2022-but-cl-is-not-recognized-as-an-internal-or-extern\n",
    "# https://stackoverflow.com/questions/73961872/cupy-cuda-failed-to-import-cupy\n",
    "# https://stackoverflow.com/questions/75355264/how-to-enable-cuda-gpu-acceleration-for-spacy-on-windows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
