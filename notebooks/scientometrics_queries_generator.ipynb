{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f01a8400-5267-4dd5-a990-dee8d8f666a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a215b64-f49e-4977-ae7c-0607c057c5e0",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557cdf4-d508-4277-8744-10035a3aa96b",
   "metadata": {},
   "source": [
    "Queries generator will use set of four lists with static words:\n",
    "1. Nouns\n",
    "2. Verbs\n",
    "3. Adjectives\n",
    "4. Gerund (participles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51621b63-98bc-49a3-981e-411bded57aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nie można znaleźć pliku ../data/raw/gerounds.csv, pomijam...\n"
     ]
    }
   ],
   "source": [
    "collections = [\"nouns\", \"verbs\", \"adjectives\", \"participles\", \"gerounds\"]\n",
    "dfs = {}\n",
    "\n",
    "for name in collections:\n",
    "    column_name = name.capitalize()\n",
    "    csv_path = f\"../data/raw/{name}.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, header=None, names=[column_name])\n",
    "        dfs[name] = df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Nie można znaleźć pliku {csv_path}, pomijam...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Wystąpił błąd podczas odczytu pliku {csv_path}: {e}\")\n",
    "\n",
    "nouns_df = dfs[\"nouns\"]\n",
    "verbs_df = dfs[\"verbs\"]\n",
    "adjectives_df = dfs[\"adjectives\"]\n",
    "participles_df = dfs[\"participles\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534d1cd9-082d-4945-be63-9929e8173a7e",
   "metadata": {},
   "source": [
    "## Query generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b39c2c1-0ee7-4ac2-a696-fb1b52c7fe0b",
   "metadata": {},
   "source": [
    "Sample code snippet to generate sentences that are candidate phrases for search queries. Which will be used in a search engine to find articles on a similar topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "297b44f1-1f2e-4cf3-9879-6f1bb6e078c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_generator(nouns, verbs, adjectives, participles, limit):\n",
    "    generated_queries = set()\n",
    "    \n",
    "    while len(generated_queries) < limit:\n",
    "        noun = random.choice(nouns)[0]\n",
    "        verb = random.choice(verbs)[0]\n",
    "        adjective = random.choice(adjectives)[0]\n",
    "        participle = random.choice(participles)[0]\n",
    "        \n",
    "        query = f\"{noun} {verb} {adjective} {participle}\"\n",
    "        \n",
    "        if query not in generated_queries:\n",
    "            generated_queries.add(query)\n",
    "            yield query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce411832-950a-4db0-8343-ae325fdf4b3d",
   "metadata": {},
   "source": [
    "### 1. Language Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd19d5b-d9c0-4d2f-9c18-45201e343915",
   "metadata": {},
   "source": [
    "First attempt to make queries more natrual with `Language Tool` library\n",
    "\n",
    "Source: [Githube](https://github.com/Findus23/pyLanguagetool) </br>\n",
    "Tutorial: [here](https://www.kaggle.com/code/yeoyunsianggeremie/how-to-use-language-tool-python-without-internet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26639521-a737-42ef-b45d-ecc642233dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from language_tool_python import LanguageTool\n",
    "\n",
    "def correct_sentence_lt(sentence: list, debug: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Corrects a sentence using LanguageTool.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The sentence to correct.\n",
    "        debug (bool, optional): A flag indicating whether to display matches, defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        str: The corrected sentence.\n",
    "    \"\"\"\n",
    "    lt = LanguageTool('en-US')\n",
    "    matches = lt.check(sentence)\n",
    "\n",
    "    if debug:\n",
    "        display(matches)\n",
    "\n",
    "    return lt.correct(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8db01f5-39d8-4d15-b853-92c542ed694b",
   "metadata": {},
   "source": [
    "### 2. Gramformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798a57f2-6111-45e6-a532-3a94c237147c",
   "metadata": {},
   "source": [
    "Second attempt to build more consistent sentences this time with `Gramformer`\n",
    "\n",
    "Source: [Githube](https://github.com/thevkrant/gramformer) </br>\n",
    "Tutorial: [here](https://www.vennify.ai/gramformer-correct-grammar-transformer-nlp/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68450b7-0416-4ddd-bd13-d38c4cb7a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gramformer import Gramformer\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    else:\n",
    "        print(f\"`Cuda` is unavailable\")\n",
    "\n",
    "def correct_sentence_gf(gf: Gramformer, sentence: str, debug = False) -> str:\n",
    "    \"\"\"\n",
    "    Corrects a sentence using Gramformer.\n",
    "\n",
    "    Args:\n",
    "        gf (Gramformer): The Gramformer object to use for correction.\n",
    "        sentence (str): The sentence to correct.\n",
    "        debug (bool, optional): A flag indicating whether to display matches, defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        str: The corrected sentence.\n",
    "    \"\"\"\n",
    "\n",
    "    return gf.correct(sentence, max_candidates=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b00c92-337c-48ca-817b-2d71e4afe8c5",
   "metadata": {},
   "source": [
    "### 1. Generate queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db8b3447-b416-4ff7-8f1e-fb8a40a96626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "queries = query_generator(nouns_df.values.tolist(), verbs_df.values.tolist(), adjectives_df.values.tolist(), participles_df.values.tolist(), 850000)\n",
    "\n",
    "queries_df = pd.DataFrame({'query': queries})\n",
    "display(len(queries_df['query'].unique()))\n",
    "\n",
    "# TEST LIBRARIES FIXING SENTENCES\n",
    "# First: dont work very well\n",
    "# Second: Make sentences better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec3b0c06-176e-4ec0-8a5d-2f2e0a2ec3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_df.drop_duplicates(subset=['query'])\n",
    "queries_df.to_csv('../data/queries_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6769b8d7-1f31-4c07-b57d-3788c6c11a9b",
   "metadata": {},
   "source": [
    "### 2. Generate embeddings for queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bc88f6-c6c2-465e-98ce-07a4c8425633",
   "metadata": {},
   "source": [
    "We generate embeddings for raw queries to expedite the target experiment. By querying the vector database ChromaDB with pre-embedded content, we offload the burden of embedding the raw query received in the request before searching and returning the K most similar titles of scientific papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b09f3902-0f5a-4b39-b1a5-0adff8e58511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98a8ccef-f142-48bf-ab2a-d8428fe6230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_df = pd.read_csv('../data/queries_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef1650e6-16c4-4930-8fd2-be0f30465676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available:  True\n",
      "Number of CUDA devices:  1\n",
      "CUDA current device:  0\n",
      "CUDA device name:  NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding titles: 100%|██████████████████████████████████████████████████████████████| 425/425 [02:47<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available: \", torch.cuda.is_available())   \n",
    "    print(\"Number of CUDA devices: \", torch.cuda.device_count())\n",
    "    print(\"CUDA current device: \", torch.cuda.current_device())\n",
    "    print(\"CUDA device name: \", torch.cuda.get_device_name(0))\n",
    "\n",
    "    # Utwórz instancję modelu SentenceTransformer\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\", device='cuda')\n",
    "else:\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\", device='cpu')\n",
    "\n",
    "\n",
    "titles = queries_df['query'].tolist()\n",
    "batch_size = 2000\n",
    "\n",
    "titles_embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(titles), batch_size), desc=\"Embedding titles\"):\n",
    "    batch = titles[i:i + batch_size]\n",
    "    batch_embeddings = model.encode(batch)\n",
    "    titles_embeddings.extend(batch_embeddings)\n",
    "\n",
    "queries_df['embedding'] = titles_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "922b64c2-2f22-4027-9eb0-4ae6368e4001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 850000/850000 [15:53<00:00, 891.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Graph Construct Encoded Reviewer</td>\n",
       "      <td>[-7.29738623e-02  5.73125109e-02 -6.29330575e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analytics Promote Elastic Interpreter</td>\n",
       "      <td>[-1.60536561e-02 -9.04399843e-04 -8.83568376e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Token Recompile Derivative Architect</td>\n",
       "      <td>[-7.27694631e-02 -2.80314535e-02  3.56670655e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Script Execute Asynchronous Debugger</td>\n",
       "      <td>[-5.32670319e-02  5.11088921e-03 -6.76202029e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scheduler Navigate Compiled Practitioner</td>\n",
       "      <td>[-4.12793793e-02 -1.11413710e-02 -3.63953374e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      query  \\\n",
       "0          Graph Construct Encoded Reviewer   \n",
       "1     Analytics Promote Elastic Interpreter   \n",
       "2      Token Recompile Derivative Architect   \n",
       "3      Script Execute Asynchronous Debugger   \n",
       "4  Scheduler Navigate Compiled Practitioner   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-7.29738623e-02  5.73125109e-02 -6.29330575e-...  \n",
       "1  [-1.60536561e-02 -9.04399843e-04 -8.83568376e-...  \n",
       "2  [-7.27694631e-02 -2.80314535e-02  3.56670655e-...  \n",
       "3  [-5.32670319e-02  5.11088921e-03 -6.76202029e-...  \n",
       "4  [-4.12793793e-02 -1.11413710e-02 -3.63953374e-...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "850000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_embedding_to_string(embedding):\n",
    "    return str(embedding)\n",
    "\n",
    "tqdm.pandas()\n",
    "queries_df['embedding'] = queries_df['embedding'].progress_apply(convert_embedding_to_string)\n",
    "\n",
    "display(queries_df.head())\n",
    "display(len(queries_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3c2d930-fca4-47c5-851e-a5e415fc7aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving progress: 100%|███████████████████████████████████████████████████████████████| 170/170 [01:34<00:00,  1.80it/s]\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 5000\n",
    "\n",
    "queries_df.iloc[:0].to_csv('../data/queries_with_embedding.csv', index=False)\n",
    "\n",
    "for i in tqdm(range(0, len(queries_df), chunk_size), desc=\"Saving progress\"):\n",
    "    df_chunk = queries_df.iloc[i:i+chunk_size]\n",
    "    df_chunk.to_csv('../data/queries_with_embedding.csv', mode='a', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
